<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="Efficient unsupervised shortcut learning detection and mitigation
              in transformers">
  <meta property="og:title" content="Efficient unsupervised shortcut learning detection and mitigation
              in transformers" />
  <meta property="og:description" content="Efficient unsupervised shortcut learning detection and mitigation
              in transformers" />
  <meta property="og:url" content="lukas-kuhn.github.io" />
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200" />
  <meta property="og:image:height" content="630" />


  <meta name="twitter:title" content="Efficient unsupervised shortcut learning detection and mitigation
              in transformers">
  <meta name="twitter:description" content="Efficient unsupervised shortcut learning detection and mitigation
              in transformers">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="Transformers, Efficient Unsupervised, Shortcut Learning">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Efficient unsupervised shortcut learning detection and mitigation in transformers</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>

<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Efficient unsupervised shortcut learning detection and mitigation
              in transformers</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="lukas-kuhn.github.io" target="_blank">Lukas Kuhn</a><sup>*1,3,4</sup>,</span>
              <span class="author-block">
                <a href="https://sari-saba-sadiya.github.io/" target="_blank">Sari
                  Saba-Sadiya</a><sup>*1</sup>,</span><br>
              <span class="author-block">
                <a href="https://hessian.ai/de/personen/joerg-schloetterer/" target="_blank">Joerg
                  Schloetterer</a><sup>2</sup>,</span>
              <span class="author-block">
                <a href="https://mlo-lab.github.io/author/florian-buettner/" target="_blank">Florian
                  Buettner</a><sup>1,3,4</sup>,</span>
              <span class="author-block">
                <a href="http://christinseifert.info/" target="_blank">Christin Seifert</a><sup>2</sup>,</span>
              <span class="author-block">
                <a href="https://www.cvai.cs.uni-frankfurt.de/team.html" target="_blank">Gemma
                  Roig</a><sup>1</sup></span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>Goethe University Frankfurt, <sup>2</sup>Philipps-University
                Marburg,<br><sup>3</sup>German Cancer Research Center (DKFZ), <sup>4</sup>German Cancer Consortium
                (DKTK)<br>ICCV 2025</span>
              <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- Arxiv PDF link -->
                <span class="link-block">
                  <a href="https://arxiv.org/pdf/2501.00942.pdf" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>
                </a>
                </span>

                <!-- Github link -->
                <span class="link-block">
                  <a href="https://github.com/Arsu-Lab/Shortcut-Detection-Mitigation-Transformers" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2501.00942" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- Youtube video -->
  <section class="hero is-small is-light">
    <div class="hero-body">
      <div class="container">
        <!-- Paper video. -->
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">

            <div class="publication-video">
              <!-- Youtube embed code here -->
              <iframe src="https://drive.google.com/file/d/156XyGqzNPdMjnoxYhCh3I0XpCO3NjYyK/preview" frameborder="0"
                allow="autoplay; encrypted-media" allowfullscreen></iframe>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End youtube video -->

  <!-- Paper abstract -->
  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              Shortcut learning, i.e., a model's reliance on undesired features not directly relevant to the task, is a
              major challenge
              that severely limits the applications of machine learning
              algorithms, particularly when deploying them to assist in
              making sensitive decisions, such as in medical diagnostics.
              In this work, we leverage recent advancements in machine
              learning to create an unsupervised framework that is capable of both detecting and mitigating shortcut
              learning in
              transformers. We validate our method on multiple datasets.
              Results demonstrate that our framework significantly improves both worst-group accuracy (samples
              misclassified
              due to shortcuts) and average accuracy, while minimizing
              human annotation effort. Moreover, we demonstrate that
              the detected shortcuts are meaningful and informative to
              human experts, and that our framework is computationally
              efficient, allowing it to be run on consumer hardware.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End paper abstract -->

  <!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@misc{kuhn2025efficientunsupervisedshortcutlearning,
      title={Efficient Unsupervised Shortcut Learning Detection and Mitigation in Transformers}, 
      author={Lukas Kuhn and Sari Sadiya and Jorg Schlotterer and Florian Buettner and Christin Seifert and Gemma Roig},
      year={2025},
      eprint={2501.00942},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2501.00942}, 
}</code></pre>
    </div>
  </section>
  <!--End BibTex citation -->


  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">

            <p>
              This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template"
                target="_blank">Academic Project Page Template</a> which was adopted from the <a
                href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
              You are free to borrow the source code of this website, we just ask that you link back to this page in the
              footer. <br> This website is licensed under a <a rel="license"
                href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
                Commons Attribution-ShareAlike 4.0 International License</a>.
            </p>

          </div>
        </div>
      </div>
    </div>
  </footer>

  <!-- Statcounter tracking code -->

  <!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

  <!-- End of Statcounter Code -->

</body>

</html>